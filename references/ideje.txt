(RM) Proposing a new method for an existing NLP problem
Kombiniranje tehnika adaptivnog predtreniranja za zadatak automatizirane provjere činjenica

Zadatak provjere činjenica se svodi na nekoliko dijelova: detekcija provjerljivih tvrdnji, provjera njihove istinitosti i objasnjavanje odluke. U radu bih se fokusirao na prva 2 zadatka koja bih formulirao kao binarne/viseklasne klasifikacijske zadatke. Ove teme su dosta slabo istrazene i sam interes za ovaj zadatak se relativno nedavno pojavio, pa ima dosta research gapa. Konkretno bih se odlucio fokusirati se na predtreniranje. U (https://arxiv.org/pdf/2004.10964.pdf) autori su pokazali da se isplati raditi adaptivno predtreniranje, a niz tehnika predtreniranja se moze naci ovdje (https://arxiv.org/abs/2003.08271). Prethodni slicni radovi su (https://aclanthology.org/2020.fever-1.5.pdf) gdje su autori koristili iskljucivo masked language modeling nad posljednjim imenovanim entitenom u tvrdnji, ali samo za podzadatak provjere istinitosti. Ovaj diplomski rad bi se razlikovao od toga po tome sto bih kombinirao nekoliko tehnika predtreniranja umjesto da koristim samo jednu i radio bih to na 2 podzadatka. Dodatno, htio bih prouciti kako drukciji pristupi finetuningu modela utjecu na performanse kod razlicitih kombinacija tehnika predtreniranja. Ovdje bih koristio fine-tuning cijelog modela, fine-tuning dijela modela i fine-tuning dijela modela pa cijelog modela.

Neka od istrazivackih pitanja koja bih si postavio su:
1. Koja od (kombinacija) tehnika predtreniranja daje najbolje rezultate?
2. Koja od (kombinacija) tehnika predtreniranja radi dovoljno dobro, a ne zahtijeva puno resursa?
3. Na koji nacin se ovo odrazava na specificnoj domeni teksta (npr. nad tvrdnjama iz medicine)?
4. Kako utjecu razlicite fine-tuning tehnike predtreniranih u odnosu na one bez predtreniranja?
5. Kako utjece koristenje adaptera nad predtreniranim modelima u odnosu na fine-tuning?

Timeline kojeg bih se drzao:
do 15.3. - review literature i eventualne reformulacije istrazivackih pitanja
do 30.3. - preprocessing podataka
do 30.4. - eksperimenti vezani uz predtreniranje
do 15.5. - eksperimenti vezani uz finetuning
do 25.5. - analiza pogresaka
do 10.6. - pisanje rada

Datasetovi za koje cu vjerojatno koristiti su (jos mogucih opcija postoji ovdje (https://arxiv.org/pdf/2108.11896.pdf)):
  - clef2023
      - https://checkthat.gitlab.io/
  - clef2022 
      - https://sites.google.com/view/clef2022-checkthat
  - clef2021
      - https://sites.google.com/view/clef2021-checkthat  
  - clef2020
      - https://sites.google.com/view/clef2020-checkthat
  - fever
      - https://fever.ai/dataset/feverous.html
  - bioclaim
      - https://www.ims.uni-stuttgart.de/forschung/ressourcen/korpora/bioclaim/
  - datasetovi iz ovog survey papera:
      - https://direct.mit.edu/tacl/article/doi/10.1162/tacl_a_00454/109469/A-Survey-on-Automated-Fact-Checking

----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
- bitno:
  - https://link.springer.com/article/10.1007/s11431-020-1647-3
  - https://arxiv.org/pdf/2004.10964.pdf

survey paper za datasetove: 
  - https://arxiv.org/pdf/2008.08854.pdf
  
https://aclanthology.org/2020.socialnlp-1.8.pdf

treba mi bolji prijevod za "claim checkworthiness detection"